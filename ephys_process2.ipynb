{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING DATASET #1\n",
      "\tsession_id: san4_run06_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_150118.rhd\n",
      "\tDESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/san4_run06_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_150118.nwb\n",
      "\tINPUT FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run06_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_150118.rhd\n",
      "READING ELECTRODE MEASUREMENT DATA FROM FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/20191107_San4_day21_EXP.xls\n",
      "CREATING ELECTRODES TABLE FROM ENTRIES IN FILE: 20191107_San4_day21_EXP.xls\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run03_optogen_N30_300au_5ms_ISI10s_centerofarray_isoflurane_191107_143024.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run03_optogen_N30_300au_5ms_ISI10s_centerofarray_isoflurane_191107_143024.nwb\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run05_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_145700.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run05_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_145700.nwb\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run06_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_150118.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run06_optogen_N30_400au_5ms_ISI5s_centerofarray_awake_191107_150118.nwb\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run07_optogen_N30_600au_5ms_ISI5s_centerofarray_awake_191107_150515.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run07_optogen_N30_600au_5ms_ISI5s_centerofarray_awake_191107_150515.nwb\n",
      "\n",
      "Reading Intan Technologies RHD2000 Data File, Version 1.5\n",
      "\n",
      "Found 32 amplifier channels.\n",
      "Found 3 auxiliary input channels.\n",
      "Found 1 supply voltage channel.\n",
      "Found 0 temperature sensors channels.\n",
      "Found 2 board ADC channels.\n",
      "Found 0 board digital input channels.\n",
      "Found 0 board digital output channels.\n",
      "\n",
      "File contains 162.792 seconds of data.  Amplifiers were sampled at 20.00 kS/s.\n",
      "CAPTURED:/mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run07_optogen_N30_600au_5ms_ISI5s_centerofarray_awake_191107_150515.nwb\n",
      "Completed chunk 0. 1.84% done. Estimated time remaining: 0:03:02. Estimated time of completion: 12:48:42\n",
      "Completed chunk 1. 3.69% done. Estimated time remaining: 0:02:48. Estimated time of completion: 12:48:32\n",
      "Completed chunk 2. 5.53% done. Estimated time remaining: 0:02:42. Estimated time of completion: 12:48:30\n",
      "Completed chunk 3. 7.37% done. Estimated time remaining: 0:02:37. Estimated time of completion: 12:48:28\n",
      "Completed chunk 4. 9.21% done. Estimated time remaining: 0:03:07. Estimated time of completion: 12:49:01\n",
      "Completed chunk 5. 11.06% done. Estimated time remaining: 0:02:55. Estimated time of completion: 12:48:52\n",
      "Completed chunk 6. 12.90% done. Estimated time remaining: 0:02:50. Estimated time of completion: 12:48:51\n",
      "Completed chunk 7. 14.74% done. Estimated time remaining: 0:02:49. Estimated time of completion: 12:48:54\n",
      "Completed chunk 8. 16.59% done. Estimated time remaining: 0:02:36. Estimated time of completion: 12:48:45\n",
      "Completed chunk 9. 18.43% done. Estimated time remaining: 0:04:01. Estimated time of completion: 12:50:15\n",
      "Completed chunk 10. 20.27% done. Estimated time remaining: 0:02:49. Estimated time of completion: 12:49:06\n",
      "Completed chunk 11. 22.11% done. Estimated time remaining: 0:03:00. Estimated time of completion: 12:49:22\n",
      "Completed chunk 12. 23.96% done. Estimated time remaining: 0:02:58. Estimated time of completion: 12:49:24\n",
      "Completed chunk 13. 25.80% done. Estimated time remaining: 0:03:54. Estimated time of completion: 12:50:27\n",
      "Completed chunk 14. 27.64% done. Estimated time remaining: 0:02:54. Estimated time of completion: 12:49:31\n",
      "Completed chunk 15. 29.49% done. Estimated time remaining: 0:02:21. Estimated time of completion: 12:49:01\n",
      "Completed chunk 16. 31.33% done. Estimated time remaining: 0:02:20. Estimated time of completion: 12:49:05\n",
      "Completed chunk 17. 33.17% done. Estimated time remaining: 0:02:20. Estimated time of completion: 12:49:08\n",
      "Completed chunk 18. 35.01% done. Estimated time remaining: 0:02:29. Estimated time of completion: 12:49:21\n",
      "Completed chunk 19. 36.86% done. Estimated time remaining: 0:03:12. Estimated time of completion: 12:50:10\n",
      "Completed chunk 20. 38.70% done. Estimated time remaining: 0:02:50. Estimated time of completion: 12:49:53\n",
      "Completed chunk 21. 40.54% done. Estimated time remaining: 0:02:06. Estimated time of completion: 12:49:13\n",
      "Completed chunk 22. 42.39% done. Estimated time remaining: 0:02:13. Estimated time of completion: 12:49:24\n",
      "Completed chunk 23. 44.23% done. Estimated time remaining: 0:02:12. Estimated time of completion: 12:49:27\n",
      "Completed chunk 24. 46.07% done. Estimated time remaining: 0:01:53. Estimated time of completion: 12:49:13\n",
      "Completed chunk 25. 47.91% done. Estimated time remaining: 0:02:20. Estimated time of completion: 12:49:44\n",
      "Completed chunk 26. 49.76% done. Estimated time remaining: 0:01:46. Estimated time of completion: 12:49:15\n",
      "Completed chunk 27. 51.60% done. Estimated time remaining: 0:01:56. Estimated time of completion: 12:49:28\n",
      "Completed chunk 28. 53.44% done. Estimated time remaining: 0:01:51. Estimated time of completion: 12:49:29\n",
      "Completed chunk 29. 55.29% done. Estimated time remaining: 0:01:48. Estimated time of completion: 12:49:30\n",
      "Completed chunk 30. 57.13% done. Estimated time remaining: 0:01:53. Estimated time of completion: 12:49:40\n",
      "Completed chunk 31. 58.97% done. Estimated time remaining: 0:01:57. Estimated time of completion: 12:49:49\n",
      "Completed chunk 32. 60.81% done. Estimated time remaining: 0:01:23. Estimated time of completion: 12:49:19\n",
      "Completed chunk 33. 62.66% done. Estimated time remaining: 0:01:11. Estimated time of completion: 12:49:10\n",
      "Completed chunk 34. 64.50% done. Estimated time remaining: 0:01:11. Estimated time of completion: 12:49:14\n",
      "Completed chunk 35. 66.34% done. Estimated time remaining: 0:01:17. Estimated time of completion: 12:49:24\n",
      "Completed chunk 36. 68.19% done. Estimated time remaining: 0:02:16. Estimated time of completion: 12:50:31\n",
      "Completed chunk 37. 70.03% done. Estimated time remaining: 0:01:48. Estimated time of completion: 12:50:10\n",
      "Completed chunk 38. 71.87% done. Estimated time remaining: 0:01:42. Estimated time of completion: 12:50:11\n",
      "Completed chunk 39. 73.71% done. Estimated time remaining: 0:01:37. Estimated time of completion: 12:50:12\n",
      "Completed chunk 40. 75.56% done. Estimated time remaining: 0:01:21. Estimated time of completion: 12:50:02\n",
      "Completed chunk 41. 77.40% done. Estimated time remaining: 0:01:31. Estimated time of completion: 12:50:20\n",
      "Completed chunk 42. 79.24% done. Estimated time remaining: 0:01:15. Estimated time of completion: 12:50:11\n",
      "Completed chunk 43. 81.09% done. Estimated time remaining: 0:01:07. Estimated time of completion: 12:50:09\n",
      "Completed chunk 44. 82.93% done. Estimated time remaining: 0:01:08. Estimated time of completion: 12:50:18\n",
      "Completed chunk 45. 84.77% done. Estimated time remaining: 0:02:06. Estimated time of completion: 12:51:31\n",
      "Completed chunk 46. 86.61% done. Estimated time remaining: 0:00:48. Estimated time of completion: 12:50:20\n",
      "Completed chunk 47. 88.46% done. Estimated time remaining: 0:00:39. Estimated time of completion: 12:50:17\n",
      "Completed chunk 48. 90.30% done. Estimated time remaining: 0:00:36. Estimated time of completion: 12:50:21\n",
      "Completed chunk 49. 92.14% done. Estimated time remaining: 0:00:36. Estimated time of completion: 12:50:30\n",
      "Completed chunk 50. 93.98% done. Estimated time remaining: 0:00:24. Estimated time of completion: 12:50:25\n",
      "Completed chunk 51. 95.83% done. Estimated time remaining: 0:00:15. Estimated time of completion: 12:50:23\n",
      "Completed chunk 52. 97.67% done. Estimated time remaining: 0:00:13. Estimated time of completion: 12:50:31\n",
      "Completed chunk 53. 99.51% done. Estimated time remaining: 0:00:01. Estimated time of completion: 12:50:27\n",
      "Completed chunk 54. 100.00% done. Estimated time remaining: 0:00:00. Estimated time of completion: 12:50:29\n",
      "No missing timestamps in data.\n",
      "Done! Elapsed time: 292.18 seconds\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run08_optogen_N30_400au_5ms_ISI5s_sideofarray_nearlargevessel_awake_191107_151823.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run08_optogen_N30_400au_5ms_ISI5s_sideofarray_nearlargevessel_awake_191107_151823.nwb\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run09_optogen_N30_600au_5ms_ISI5s_sideofarray_nearlargevessel_awake_191107_152155.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run09_optogen_N30_600au_5ms_ISI5s_sideofarray_nearlargevessel_awake_191107_152155.nwb\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run10_optogen_N30_400au_5ms_ISI5s_sideofarray_lessbloodregion_awake_191107_153141.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run10_optogen_N30_400au_5ms_ISI5s_sideofarray_lessbloodregion_awake_191107_153141.nwb\n",
      "\tELECTRODE MEASUREMENT SOURCE FILE: /mnt/e/temp/Devor-gdrive/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/ephys/san4_run11_optogen_N30_600au_5ms_ISI5s_sideofarray_lessbloodregion_awake_191107_153442.rhd\n",
      "\tELECTRODE MEASUREMENT DESTINATION FILE: /mnt/e/temp/Devor-gdrive/output/20191017_Chronic implant_SL2701_San4/20191107_San4_day21/san4_run11_optogen_N30_600au_5ms_ISI5s_sideofarray_lessbloodregion_awake_191107_153442.nwb\n"
     ]
    }
   ],
   "source": [
    "# CREATED: 17-NOV-2022\n",
    "# LAST EDIT: 22-NOV-2022\n",
    "# AUTHOR: DUANE RINEHART, MBA (drinehart@ucsd.edu)\n",
    "\n",
    "# IMPLEMENTS CONVERSION OF EXTRACELLULAR ELECTROPHYSIOLOGY DATASETS TO NEURODATA WITHOUT BORDERS (NWB) nbformat\n",
    "# REQUIREMENT BY GRANT TO UPLOAD DATA IN OPEN FORMAT TO PUBIC-ACCESSIBLE REPOSITORY\n",
    "\n",
    "import os, math, time, pynwb\n",
    "from pathlib import Path, PurePath, PureWindowsPath\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.tz import tzlocal\n",
    "import pandas as pd\n",
    "from pathlib import PurePath\n",
    "\n",
    "from ConvertIntanToNWB import convert_to_nwb\n",
    "\n",
    "#################################################################\n",
    "# APP CONSTANTS\n",
    "excel_file = 'input.xlsx'\n",
    "base_path = Path('/mnt/e/temp/Devor-gdrive/')\n",
    "infile = Path(base_path, excel_file)\n",
    "debug = True\n",
    "#################################################################\n",
    "\n",
    "def load_data():\n",
    "    '''Used for meta-data loading'''\n",
    "    lstNWBFields = ['session_id', 'age', 'subject_description', 'species', 'genotype', 'sex', 'subject_strain', 'subject_weight', 'session_description', 'subject_id', 'pharmacology', 'date_of_birth(YYYY-MM-DD)', 'src_folder_directory', 'stimulus_notes_include', 'stimulus_notes_paradigm', 'stimulus_notes_direct_electrical_stimulation', 'stimulus_notes_direct_electrical_stimulation_paradigm', 'pharmacology_notes_anesthetized_during_recording', 'electrode_recordings', 'electrode_recordings_type', 'electrode_recordings_contact_material', 'electrode_recordings_substrate'] #headers I need\n",
    "\n",
    "    lstExtractionFields = pd.read_excel(infile, sheet_name=\"auto\", usecols=lstNWBFields) #just extract columns/fields I need\n",
    "    return lstExtractionFields\n",
    "\n",
    "\n",
    "def get_measurements_data(src_folder_directory: str, channel_map_recordings_file: str, debug: bool = False):\n",
    "    '''Used for electrode measurements table processing'''\n",
    "    electrode_data = None\n",
    "    if Path(channel_map_recordings_file).suffix == '.xls':\n",
    "        #Note: must use 'PureWindowsPath' for org dataset (base_directory)\n",
    "        #N.B. must use Path to extract data\n",
    "        base_directory = PureWindowsPath(src_folder_directory).parts[:-1] #remove last part of path\n",
    "        input_filename = Path(base_path, *base_directory, channel_map_recordings_file)\n",
    "\n",
    "        lstNWBFields = ['date', 'runnum', 'array', 'set', 'mapping', 'ep', 'epFile', 'stim', 'stimType', 'stimCondition', 'stimLocation', 'stimFile', 'imaging', 'imagingFile', 'imagingType', 'imagingCond', 'imagingLocation', 'webcam', 'webcamFile', 'trialAvg', 'trialAvgType', 'trialAvgCond', 'animal', 'comment'] #headers I need\n",
    "\n",
    "        if debug == True:\n",
    "            print(f\"READING ELECTRODE MEASUREMENT DATA FROM FILE: {input_filename}\")\n",
    "        electrode_data = pd.read_excel(input_filename, usecols=lambda x: x in lstNWBFields) #just extract columns/fields I need (ignore if not present - lambda part)\n",
    "    else:\n",
    "        # PROCEDURES FOR .cfg FILE\n",
    "        input_filename = Path(src_folder_directory, channel_map_recordings_file)\n",
    "\n",
    "        #NEED PROCEDURES TO PROCESS .cfg FILES\n",
    "    return electrode_data\n",
    "\n",
    "\n",
    "def process_electrode_measurements(input_filename: str, raw_src_folder_directory: str, stimulus_notes: str, debug: bool = False):\n",
    "    '''Used for electrode measurements table processing\n",
    "\n",
    "    Captures input/output location path & filename and calls conversion script Intan -> NWB'''\n",
    "    #Note: must use 'PureWindowsPath' for org dataset (raw_src_folder_directory)\n",
    "    output_folder = PureWindowsPath(raw_src_folder_directory).parts[:-1]\n",
    "\n",
    "    output_filename = None\n",
    "    filename = PureWindowsPath(input_filename) #wrong extension; replace with 'nwb'\n",
    "    session_description = str(filename.with_suffix('')) #must be unique (str)\n",
    "\n",
    "    input_filename = Path(base_path, *output_folder, 'ephys', input_filename)\n",
    "    raw_filename = input_filename.stem #just filename without extension\n",
    "    output_filename = str(raw_filename) + '.nwb' #add extension for output filename\n",
    "\n",
    "    dest_path = str(Path(base_path, 'output', *output_folder, output_filename)) #path must be string for Itan converter\n",
    "    os.makedirs(Path(base_path, 'output', *output_folder), exist_ok = True)\n",
    "\n",
    "    subject = None #temp fix\n",
    "    surgery = None #temp fix\n",
    "    pharmacology = None #temp fix\n",
    "    manual_start_time = '' #temp fix\n",
    "    ##################################################################################\n",
    "    if debug == True:\n",
    "        print(f'\\tELECTRODE MEASUREMENT SOURCE FILE: {input_filename}')\n",
    "        print(f'\\tELECTRODE MEASUREMENT DESTINATION FILE: {dest_path}')\n",
    "\n",
    "    #Note: As of 21-NOV-2022, 'merge_files' does not work. Each file will need conversion and merging\n",
    "\n",
    "    if os.path.isfile(dest_path) != True: #file conversion completed\n",
    "        convert_to_nwb(intan_filename=str(input_filename),\n",
    "                       nwb_filename=dest_path,\n",
    "                       session_description=session_description,\n",
    "                       blocks_per_chunk=1000,\n",
    "                       use_compression=True,\n",
    "                       compression_level=4,\n",
    "                       lowpass_description='Unknown lowpass filtering process',\n",
    "                       highpass_description='Unknown lowpass filtering process',\n",
    "                       merge_files=False,\n",
    "                       subject=subject,\n",
    "                       surgery=surgery,\n",
    "                       stimulus_notes=stimulus_notes,\n",
    "                       pharmacology=pharmacology,\n",
    "                       manual_start_time=None)\n",
    "\n",
    "\n",
    "def get_subject(age, subject_description, genotype, sex, species, subject_id, subject_weight, date_of_birth, subject_strain):\n",
    "    '''Used for meta-data '''\n",
    "    if isinstance(age, str) != True:\n",
    "        subject_age = \"P\" + str(age) #ISO 8601 Duration format\n",
    "\n",
    "    dob = date_of_birth.to_pydatetime() #convert pandas timestamp to python datetime format\n",
    "    if isinstance(dob.year, int) and isinstance(dob.month, int) and isinstance(dob.day, int) == True:\n",
    "        date_of_birth = datetime(dob.year, dob.month, dob.day, tzinfo=tzlocal())\n",
    "    else:\n",
    "        date_of_birth = None\n",
    "\n",
    "    subject = pynwb.file.Subject(age=subject_age,\n",
    "                             description=subject_description,\n",
    "                             genotype=str(genotype),\n",
    "                             sex=sex,\n",
    "                             species=species,\n",
    "                             subject_id=subject_id,\n",
    "                             weight=subject_weight,\n",
    "                             date_of_birth=date_of_birth,\n",
    "                             strain=subject_strain\n",
    "                            )\n",
    "    return subject\n",
    "\n",
    "\n",
    "lstRecords = load_data().to_dict('records') #creates list of dictionaries\n",
    "\n",
    "for cnt, dataset in enumerate(lstRecords):\n",
    "    print(f\"PROCESSING DATASET #{cnt+1}\")\n",
    "    print(f\"\\tsession_id: {dataset['session_id']}\")\n",
    "\n",
    "    age = dataset['age']\n",
    "    subject_description = dataset['subject_description']\n",
    "    genotype = dataset['genotype']\n",
    "    sex = dataset['sex']\n",
    "    species = dataset['species']\n",
    "    subject_id = dataset['subject_id']\n",
    "    subject_weight = dataset['subject_weight']\n",
    "    date_of_birth = dataset['date_of_birth(YYYY-MM-DD)']\n",
    "    subject_strain = dataset['subject_strain']\n",
    "\n",
    "    #CONCATENATE STIMULUS NOTES\n",
    "    stimulus_notes = 'NA'\n",
    "    if dataset['stimulus_notes_include'] == 1: #1 (include) or 2 (do not include)\n",
    "        stimulus_notes = \"Stimulus paradigm: \" + str(dataset['stimulus_notes_paradigm']) + \"; \"\n",
    "        if dataset['stimulus_notes_direct_electrical_stimulation'] == 1:\n",
    "            stimulus_notes += \"Direct electrical stimulation paradigm: \" + str(dataset['stimulus_notes_direct_electrical_stimulation_paradigm']) + \"; \"\n",
    "    ##################################################################################\n",
    "    subject = get_subject(age,\n",
    "                          subject_description,\n",
    "                          genotype,\n",
    "                          sex,\n",
    "                          species,\n",
    "                          subject_id,\n",
    "                          subject_weight,\n",
    "                          date_of_birth,\n",
    "                          subject_strain)\n",
    "    ##################################################################################\n",
    "\n",
    "    ##################################################################################\n",
    "    output_filename = None\n",
    "    session_id = dataset['session_id']\n",
    "    filename = Path(session_id) #wrong extension; replace with 'nwb'\n",
    "    output_filename = filename.with_suffix('.nwb')\n",
    "    dest_path = str(PurePath('/mnt/e/temp/Devor-gdrive/output/', output_filename)) #path must be string for Itan converter\n",
    "    print(f'\\tDESTINATION FILE: {dest_path}')\n",
    "\n",
    "    src_path_supplement = PureWindowsPath(dataset['src_folder_directory'])\n",
    "\n",
    "    input_filename = str(PurePath('/mnt/e/temp/Devor-gdrive/', src_path_supplement, session_id))\n",
    "    print(f'\\tINPUT FILE: {input_filename}')\n",
    "    ##################################################################################\n",
    "\n",
    "    ##################################################################################\n",
    "    # PROCESS META-DATA\n",
    "    session_description = dataset['session_description']\n",
    "    pharmacology = None #NEED DESTINATION FIELD FOR NWB FILE\n",
    "    if dataset['pharmacology_notes_anesthetized_during_recording'] == 1:\n",
    "        pharmacology = dataset['pharmacology']\n",
    "\n",
    "    surgery = None #NEED DESTINATION FIELD FOR NWB FILE\n",
    "    manual_start_time = None #NEED DESTINATION FIELD FOR NWB FILE\n",
    "\n",
    "    if os.path.isfile(dest_path) != True: #file conversion completed\n",
    "        convert_to_nwb(intan_filename=input_filename,\n",
    "                   nwb_filename=dest_path,\n",
    "                   session_description=session_description,\n",
    "                   blocks_per_chunk=1000,\n",
    "                   use_compression=True,\n",
    "                   compression_level=4,\n",
    "                   lowpass_description='Unknown lowpass filtering process',\n",
    "                   highpass_description='Unknown lowpass filtering process',\n",
    "                   merge_files=False,\n",
    "                   subject=subject,\n",
    "                   surgery=surgery,\n",
    "                   stimulus_notes=stimulus_notes,\n",
    "                   pharmacology=pharmacology,\n",
    "                   manual_start_time=manual_start_time)\n",
    "    ##################################################################################\n",
    "\n",
    "    ##################################################################################\n",
    "    # CREATE/CONVERT ELECTRODES TABLE(S)\n",
    "    # capture from main input.xlsx (loop); LIST OF RECORDINGS IN .xls or .cfg FILE\n",
    "    src_folder_directory = dataset['src_folder_directory']\n",
    "    electrode_recordings = dataset['electrode_recordings']\n",
    "    electrode_recordings_type = dataset['electrode_recordings_type'] #NEED DESTINATION FIELD FOR NWB FILE\n",
    "    electrode_recordings_contact_material = dataset['electrode_recordings_contact_material'] #NEED DESTINATION FIELD FOR NWB FILE\n",
    "\n",
    "    channel_map_recordings_file = electrode_recordings #Excel (or .cfg) containing locations of electrode measurement recordings\n",
    "    lstRecords = get_measurements_data(src_folder_directory, channel_map_recordings_file, debug)\n",
    "    if isinstance(lstRecords, pd.DataFrame):\n",
    "        dictRecords = lstRecords.to_dict('records') #creates list of dictionaries\n",
    "\n",
    "        ##################################################################################\n",
    "        if debug == True:\n",
    "            print(f'CREATING ELECTRODES TABLE FROM ENTRIES IN FILE: {channel_map_recordings_file}')\n",
    "\n",
    "        for record in dictRecords:\n",
    "            stimulus_notes = None\n",
    "\n",
    "            input_filename = record['epFile']\n",
    "            if record['stim'] == 1:\n",
    "                stimulus_notes = record['stimType']\n",
    "            process_electrode_measurements(input_filename, src_folder_directory, stimulus_notes)\n",
    "        ##################################################################################\n",
    "\n",
    "    else:\n",
    "        print(\"ERROR READING CHANNEL MAP RECORDINGS FILE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pipeline38",
   "language": "python",
   "display_name": "pipeline38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
